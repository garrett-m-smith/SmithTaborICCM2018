fakedat$rt<-rt
fakedat
}
nsim<-10
tval<-rep(NA,nsim) # saving t-vals
for(i in 1:nsim){
dat<-gen_fake_lnorm(beta=c(6, 0.031+0.072))
mfake<-lmer(log(rt)~x+(1+x|subj)+(1+x|item),dat)
tval[i]<-summary(mfake)$coefficients[2,3]
}
mean(abs(tval)>2)
nsim<-10
tval<-rep(NA,nsim) # saving t-vals
for(i in 1:nsim){
dat<-gen_fake_lnorm(beta=c(6, -0.031-0.072))
mfake<-lmer(log(rt)~x+(1+x|subj)+(1+x|item),dat)
tval[i]<-summary(mfake)$coefficients[2,3]
}
mean(abs(tval)>2)
exp(-0.1)
nsim<-100
exp(6-01.)
exp(6-0.1)
nsim<-100
tval<-rep(NA,nsim) # saving t-vals
for(i in 1:nsim){
dat<-gen_fake_lnorm(beta=c(6, -0.031-0.072))
mfake<-lmer(log(rt)~x+(1+x|subj)+(1+x|item), dat)
tval[i]<-summary(mfake)$coefficients[2,3]
}
mean(abs(tval)>2)
log(5)
log(6)
log(5)
log(500) - log(505)
nsim<-10
tval<-rep(NA,nsim) # saving t-vals
for(i in 1:nsim){
dat<-gen_fake_lnorm(beta=c(6, 0.01))
mfake<-lmer(log(rt)~x+(1+x|subj)+(1+x|item), dat)
tval[i]<-summary(mfake)$coefficients[2,3]
}
mean(abs(tval)>2)
log(500) - log(510)
nsim<-10
tval<-rep(NA,nsim) # saving t-vals
for(i in 1:nsim){
dat<-gen_fake_lnorm(beta=c(6, 0.02))
mfake<-lmer(log(rt)~x+(1+x|subj)+(1+x|item), dat)
tval[i]<-summary(mfake)$coefficients[2,3]
}
mean(abs(tval)>2)
nsim<-100
tval<-rep(NA,nsim) # saving t-vals
for(i in 1:nsim){
dat<-gen_fake_lnorm(beta=c(6, 0.02))
mfake<-lmer(log(rt)~x+(1+x|subj)+(1+x|item), dat)
tval[i]<-summary(mfake)$coefficients[2,3]
}
mean(abs(tval)>2)
exp(log(500) + 0.05)
nsim<-100
tval<-rep(NA,nsim) # saving t-vals
for(i in 1:nsim){
dat<-gen_fake_lnorm(beta=c(6, 0.05))
mfake<-lmer(log(rt)~x+(1+x|subj)+(1+x|item), dat)
tval[i]<-summary(mfake)$coefficients[2,3]
}
mean(abs(tval)>2)
for(i in 1:nsim){
dat<-gen_fake_lnorm(beta=c(6, 0.05), nsubj = 120)
mfake<-lmer(log(rt)~x+(1+x|subj)+(1+x|item), dat)
tval[i]<-summary(mfake)$coefficients[2,3]
}
mean(abs(tval)>2)
nsim<-100
tval<-rep(NA,nsim) # saving t-vals
for(i in 1:nsim){
dat<-gen_fake_lnorm(beta=c(6, 0.1), nsubj = 100)
mfake<-lmer(log(rt)~x+(1+x|subj)+(1+x|item), dat)
tval[i]<-summary(mfake)$coefficients[2,3]
}
mean(abs(tval)>2)
exp(0.5)
nsim<-100
tval<-rep(NA,nsim) # saving t-vals
for(i in 1:nsim){
dat<-gen_fake_lnorm(beta=c(6, 0.1), nsubj = 100, sigma_e = 1.0)
mfake<-lmer(log(rt)~x+(1+x|subj)+(1+x|item), dat)
tval[i]<-summary(mfake)$coefficients[2,3]
}
mean(abs(tval)>2)
retrodesign <- function(A, s, alpha=.05, df=Inf, n.sims=10000){
z <- qt(1-alpha/2, df)
p.hi <- 1 - pt(z-A/s, df)
p.lo <- pt(-z-A/s, df)
power <- p.hi + p.lo
typeS <- p.lo/power
estimate <- A + s*rt(n.sims,df)
significant <- abs(estimate) > s*z
exaggeration <- mean(abs(estimate)[significant])/A
return(list(power=power, typeS=typeS, exaggeration=exaggeration))
}
retrodesign(0.031, 0.010)
retrodesign(0.031, 0.010, df=166)
retrodesign(0.072, 0.040, df=166)
retrodesign(0.05, 0.1, df=127)
retrodesign(0.05, 0.05, df=127)
retrodesign(0.05, 0.01, df=127)
retrodesign(0.05, 0.02, df=127)
retrodesign(0.05, 0.026, df=127)
retrodesign(0.05, 0.026, df=99)
retrodesign(20, 20)
retrodesign(20, 10)
retrodesign(20, 5)
retrodesign(10, 5)
retrodesign(10, 4)
562-488
retrodesign(74, 74)
retrodesign(74, 35)
retrodesign(74, 24)
retrodesign <- function(A, s, alpha=.05, df=Inf, n.sims=10000){
z <- qt(1-alpha/2, df)
p.hi <- 1 - pt(z-A/s, df)
p.lo <- pt(-z-A/s, df)
power <- p.hi + p.lo
typeS <- p.lo/power
estimate <- A + s*rt(n.sims,df)
significant <- abs(estimate) > s*z
exaggeration <- mean(abs(estimate)[significant])/A
return(list(power=power, typeS=typeS, exaggeration=exaggeration))
}
retrodesign(0.031, 0.010) # Sandra's It. study
retrodesign(-6, 3)
retrodesign(-6, 2)
n <- rnorm(100)
qqplot(n)
qqnorm(n)
qqline(n)
nn <- rlnorm(100)
qqnorm(nn)
qqline(nn)
qqnorm(log(nn))
qqline(log(nn))
qt(0.5, 1.326)
qt(0.05, 1.326)
?pt
1 - pt(1.326,df = 58)
install.packages("IBEX.to-1.R", lib="~/Downloads/")
install.packages("IBEX.to-1.R", lib="~/Downloads/IBEX.to-1.R/")
install.packages("IBEX.to-1.R", lib="~/Downloads/IBEX.to.R_0.9.tar.gz")
library(IBEX.to-1.R)
library("IBEX.to-1.R"")
library("IBEX.to-1.R")
library(`IBEX.to-1.R`)
library(IBEX.to.R)
?install.packages
install.packages("~/Downloads/IBEX.to.R_0.9.tar", repos=NULL, type='source')
library(IBEX.to.R)
??harmonic
psych::harmonic.mean(c(10, 30, 80))
psych::harmonic.mean(c(5, 14, 10, 6))
mean(c(5, 14, 10, 6))
contr.helmert(3)
s <- 100
n <- 1:200
plot(sqrt(n), s/sqrt(n))
n <- 1:1000
plot(sqrt(n), s/sqrt(n))
plot(sqrt(n), s/sqrt(n), 'l')
s/sqrt(n)
install.packages('foreign', dependencies = T)
foreign::read.spss()
contr.sum(2)
contr.sum(3)
solve(contr.sum(3))
solve(contr.sum(3)[:,1:2])
solve(matrix(c(1, 0, 0, 1), byrow = T))
solve(matrix(c(1, 0, 0, 1), byrow = T, nrow=2))
A = matrix(c(2, 3, 1, -2), byrow = T, nrow = 2)
A
rhs = c(-1, 3)
solve(A) %*% rhs
install.packages('rwiener', dependencies = T)
install.packages('RWiener', dependencies = T)
?trimws
?merge
library(ggplot2)
data <- read.csv('~/Downloads/data.csv')
head(data)
str(data)
ggplot(data, aes(x=Name.in.English, y=log(Number.of.speakers))) + geom_point()
summary(data$Number.of.speakers)
data2 <- droplevels(data[!is.na(data),])
?is.na
nrow(is.na(data))
nrow(data[where[is.na(data)]])
nrow(data[where(is.na(data)]))
data2 <- droplevels(na.omit(data))
str(data2)
ggplot(data2, aes(Degree.of.endangerment)) + geom_hist()
ggplot(data2, aes(Degree.of.endangerment)) + geom_histogram()
ggplot(data2, aes(Degree.of.endangerment)) + geom_bar()
levels(data2$Degree.of.endangerment)
library(ez)
data <- read.csv('~/Desktop/Scrap/OrigamiExperimentResults.csv')
head(data)
str(data)
data <- read.csv('~/Desktop/Scrap/OrigamiExperimentResults.csv', header=F)
head(data)
names(data)[1:2] <- c('AV', 'Gender')
head(data)
View(data)
names(data)[13] <- c('Total')
results <- ezANOVA(data, dv = Total, between = .(AV, Gender), return_aov = T)
data$Participant <- seq_along(data)
head(data)
results <- ezANOVA(data, dv = Total, wid = Participant, between = .(AV, Gender), return_aov = T)
data <- droplevels(data[-2,:])
data <- droplevels(data[-2,])
results <- ezANOVA(data, dv = Total, wid = Participant, between = .(AV, Gender), return_aov = T)
results
library(multcomp)
?glht
glht(results$aov, linfct=mcp(gender = 'Tukey'))
glht(results$aov, linfct=mcp(Gender = 'Tukey'))
library(lsmeans)
lsmeans(results$aov ~ Gender + AV)
?lsmeans
lsmeans(results$aov ~ Gender | AV)
lsmeans(results$aov, ~ Gender | AV)
lsmeans(results$aov, pairwise ~ Gender | AV)
aggregate(Total ~ AV + Gender, data, FUN = mean)
aggregate(Total ~ AV + Gender, data, FUN = sd)
results
data <- read.csv('~/Desktop/Scrap/EmmaFinalData.csv')
View(data)
library(ezANOVA)
library(ez)
View(data)
View(data)
names(data)
ezANOVA(data, dv=Average.Time, wid=Participant.., within=.(Condition))
library(lsmeans)
results <- ezANOVA(data, dv=Average.Time, wid=Participant.., within=.(Condition), return_aov = T)
results
lsmeans(results$aov, pairwise ~ Condition)
lsmeans(results$aov, pairwise ~ Condition, adjust='bonferroni')
results <- ezANOVA(data, dv=log(Average.Time), wid=Participant.., within=.(Condition), return_aov = T)
results
library(lsmeans)
lsmeans(results$aov, pairwise ~ Condition, adjust='bonferroni')
library(ggplot2)
ggplot(data, aes(x=Condition, y=Average.Time)) + stat.summary(fun.data=mean_cl_boot)
ggplot(data, aes(x=Condition, y=Average.Time)) + stat_summary(fun.data=mean_cl_boot)
ggplot(data, aes(x=Condition, y=Average.Time)) + geom_point(alpha=0.5) + stat_summary(fun.data=mean_cl_boot)
ggplot(data, aes(x=Condition, y=Average.Time)) + geom_point(alpha=0.25) + stat_summary(fun.data=mean_cl_boot)
ggplot(data, aes(x=Condition, y=Average.Time)) + geom_point(alpha=0.25)
ggplot(data, aes(x=Condition, y=Average.Time)) + geom_point(alpha=0.25) +
stat_summary(fun.data=mean_cl_boot)
ggplot(data, aes(x=Condition, y=log(Average.Time))) + geom_point(alpha=0.25) +
stat_summary(fun.data=mean_cl_boot)
ggplot(data, aes(x=Condition, y=log(Average.Time))) + geom_point(alpha=0.25) +
stat_summary(fun.data=mean_cl_boot) + theme_light()
lsmeans(results$aov, pairwise ~ Condition, adjust='bonferroni')
results <- ezANOVA(data, dv=Average.Time, wid=Participant.., within=.(Condition), return_aov = T)
results
lsmeans(results, pairwise ~ Condition, adjust='bonferroni')
results <- ezANOVA(data, dv=Average.Time, wid=Participant.., within=.(Condition), return_aov = T)
results
lsmeans(results$aov, pairwise ~ Condition, adjust='bonferroni')
lsmeans(results$aov, pairwise ~ Condition, adjust='Tukey')
??lsmeans
lsmeans(results$aov, pairwise ~ Condition, adjust='bonferroni')
pd <- rnorm(100)
rm(pd)
pa = 0.25
pb = 1 - pa
pda = 0.5
pdb = 0.25
pad = pda * pa
pad
data_phase1 <- matrix(c(38, 16335650, 17, 14794210), byrow = T)
data_phase1
data_phase1 <- matrix(c(38, 16335650, 17, 14794210), byrow = T, nrow = 2)
data_phase1
fisher.test(data_phase1)
d <- matrix(c(31, 50, 70, 17), byrow = T, nrow = 2)
chisq.test(d)
fisher.test(d)
library(Hmisc)
d <- spss.get('~/Downloads/Untitled2.sav')
head(d)
d2 <- d[1:,]
d2 <- d[2:6,]
d2
chisq.test(d2)
?chisq.test
chisq.test(d2, simulate.p.value = T)
fisher.test(d2)
fisher.test(d)
chisq.test(d)
fisher.test(d)
fisher.test(d2)
chisq.test(d2)
chisq.test(d2, simulate.p.value = T, B=10000)
prop.test(d2)
sl <- read.csv('~/Downloads/PSYC 2100WQ - Data Analysis - Sheet1.csv')
sl
sl$EaNight <- 0
sl$EaNight <- c(4.5, 6.5, 9, 4.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5)
sl$LastNight <- c(6.5, 6.5, 9, 2.5, 4.5, 6.5, 6.5, 6.5, 6.5, 8.5)
cor.test(sl$EaNight, sl$Total.Score)
cor.test(sl$LastNight, sl$Total.Score)
plot(sl$LastNight, sl$Total.Score)
plot(sl$EaNight, sl$Total.Score)
d <- matrix(c(15, 2, 20, 4, 23, 11, 14, 9, 9, 0, 19, 11, 3, 1, 22, 12, 8, 2, 15, 4), nrow = 2, byrow = T)
d
d <- matrix(c(15, 2, 20, 4, 23, 11, 14, 9, 9, 0, 19, 11, 3, 1, 22, 12, 8, 2, 15, 4), nrow = 10, byrow = T)
d
fisher.test(d)
chisq.test(d, simulate.p.value = T, B=1e5)
cor.test(d)
cor.test(d[:,1], d[:,2])
cor.test(d[,1], d[,2])
library(Hmisc)
??sav
d <- spss.get('~/Downloads/Stressphysicaldata.sav')
d
chisq.test(d)
chisq.test(d[2:,])
chisq.test(d[2:,:])
chisq.test(d[2:7,:])
chisq.test(d[2:7,])
str(d)
d[2:7,] <- as.numeric(d[2:7,])
d[2:7,] <- as.numeric(unlist(d[2:7,]))
d
d <- spss.get('~/Downloads/Stressphysicaldata.sav')
d[3:7,] <- as.numeric(unlist(d[3:7,]))
d
chisq.test(d[3:7,])
str(d)
?spss.get
library(foreign)
d <- read.spss('~/Downloads/Stressphysicaldata.sav')
d
d <- as.data.frame(read.spss('~/Downloads/Stressphysicaldata.sav'))
d
str(d)
chisq.test(d[2:7,])
d[2:7,]
chisq.test(d[3:7,])
chisq.test(d[,3:7])
chisq.test(d[,2:7])
d
fisher.test(d[,2:7])
chisq.test(d[,2:7], simulate.p.value = T)
table(d[1:5,], d[6:10])
table(d[1:5,], d[6:10,])
xtabs(d[1:5,], d[6:10,])
xtabs(d[1:5,2:7], d[6:10,2:7])
d
d2 <- read.csv('~/Downloads/PSYC 2100WQ - Data Analysis - Sheet1.csv')
d2
d
d <- matrix(c(5, 45, 0, 48), byrow = T, nrow = 2)
d
chisq.test(d)
chisq.test(d, simulate.p.value = T, B=10000)
fisher.test(d)
?fisher.test
d <- data.frame(Condition=c('tossed', 'thrown'), ProcessingTime=c(159.073, 149.794), SD=c(27.692, 24.698), PercentGrammatical=c(244/2000, 13/2000))
d
library(ggplot2)
library(ggplot2)
ggplot(d, aes(Condition, ProcessingTime)) +
geom_pointrange(aes(ymin=ProcessingTime-SD, ymax=ProcessingTime+SD))
d
str(d)
d$Condition <- relevel(d$Condition, 'tossed')
ggplot(d, aes(Condition, ProcessingTime)) +
geom_pointrange(aes(ymin=ProcessingTime-SD, ymax=ProcessingTime+SD))
d$SE <- d$SD / sqrt(2000)
ggplot(d, aes(Condition, ProcessingTime)) +
geom_pointrange(aes(ymin=ProcessingTime-SE, ymax=ProcessingTime+SE))
ggplot(d, aes(Condition, ProcessingTime)) +
geom_pointrange(aes(ymin=ProcessingTime-2*SE, ymax=ProcessingTime+2*SE))
ggplot(d, aes(Condition, ProcessingTime)) +
geom_pointrange(aes(ymin=ProcessingTime-2*SE, ymax=ProcessingTime+2*SE)) +
geom_classic()
ggplot(d, aes(Condition, ProcessingTime)) +
geom_pointrange(aes(ymin=ProcessingTime-2*SE, ymax=ProcessingTime+2*SE)) +
theme_classic()
ggplot(d, aes(Condition, ProcessingTime)) +
geom_pointrange(aes(ymin=ProcessingTime-2*SE, ymax=ProcessingTime+2*SE)) +
geom_point(aes(y=PercentGrammatical)) +
scale_y_continuous(sec.axis = sec.axis(~.))
ggplot(d, aes(Condition, ProcessingTime)) +
geom_pointrange(aes(ymin=ProcessingTime-2*SE, ymax=ProcessingTime+2*SE)) +
geom_point(aes(y=PercentGrammatical)) +
scale_y_continuous(sec.axis = sec_axis(~.))
ggplot(d, aes(Condition, ProcessingTime)) +
geom_pointrange(aes(ymin=ProcessingTime-2*SE, ymax=ProcessingTime+2*SE)) +
geom_point(aes(y=PercentGrammatical)) +
scale_y_continuous(sec.axis = sec_axis(~.*0.1, name='Percent grammatical parse'))
ggplot(d, aes(Condition, ProcessingTime)) +
geom_pointrange(aes(ymin=ProcessingTime-2*SE, ymax=ProcessingTime+2*SE)) +
geom_point(aes(y=PercentGrammatical)) +
scale_y_continuous(sec.axis = sec_axis(name='Percent grammatical parse'))
ggplot(d, aes(Condition, ProcessingTime)) +
geom_pointrange(aes(ymin=ProcessingTime-2*SE, ymax=ProcessingTime+2*SE)) +
ggtitle('Mean processing times with 95\% CIs')
ggplot(d, aes(Condition, ProcessingTime)) +
geom_pointrange(aes(ymin=ProcessingTime-2*SE, ymax=ProcessingTime+2*SE)) +
ggtitle('Mean processing times with 95% CIs')
ggplot(d, aes(Condition, ProcessingTime)) +
geom_pointrange(aes(ymin=ProcessingTime-2*SE, ymax=ProcessingTime+2*SE)) +
ggtitle('Mean processing times with 95% CIs') +
theme_classic()
ggplot(d, aes(Condition, PercentGrammatical)) +
geom_pointrange(aes(ymin=ProcessingTime-2*SE, ymax=ProcessingTime+2*SE)) +
ggtitle('Percentage of runs settling on the grammatical parse') +
theme_classic()
ggplot(d, aes(Condition, PercentGrammatical)) +
ggtitle('Percentage of runs settling on the grammatical parse') +
theme_classic()
ggplot(d, aes(Condition, PercentGrammatical)) + geom_point()
ggplot(d, aes(Condition, PercentGrammatical)) + geom_point() +
ggtitle('Percentage of runs settling on the grammatical parse') +
theme_classic()
d <- data.frame(Condition=c('tossed', 'thrown'), ProcessingTime=c(159.073, 149.794),
SD=c(27.692, 24.698), PercentGrammatical=c(244/2000*100, 13/2000*100))
d$Condition <- relevel(d$Condition, 'tossed')
d$SE <- d$SD / sqrt(2000)
ggplot(d, aes(Condition, ProcessingTime)) +
geom_pointrange(aes(ymin=ProcessingTime-2*SE, ymax=ProcessingTime+2*SE)) +
ggtitle('Mean processing times with 95% CIs') +
theme_classic()
ggplot(d, aes(Condition, PercentGrammatical)) + geom_point() +
ylim(0, 14) +
ggtitle('Percentage of runs settling on the grammatical parse') +
theme_classic()
ggplot(d, aes(Condition, PercentGrammatical)) + geom_point() +
ylim(0, 13) +
ggtitle('Percentage of runs settling on the grammatical parse') +
theme_classic()
ggplot(d, aes(Condition, PercentGrammatical)) + geom_point(size=1.5) +
ylim(0, 13) +
ggtitle('Percentage of runs settling on the grammatical parse') +
theme_classic()
ggplot(d, aes(Condition, PercentGrammatical)) + geom_point(size=2.5) +
ylim(0, 13) +
ggtitle('Percentage of runs settling on the grammatical parse') +
theme_classic()
ggplot(d, aes(Condition, PercentGrammatical)) + geom_point(size=2.5) +
ylim(0, 13) +
ggtitle('Percentage of runs settling on the grammatical parse') +
theme_classic(size=18)
ggplot(d, aes(Condition, PercentGrammatical)) + geom_point(size=2.5) +
ylim(0, 13) +
ggtitle('Percentage of runs settling on\nthe grammatical parse') +
theme_classic(size=18)
ggplot(d, aes(Condition, PercentGrammatical)) + geom_point(size=2.5) +
ylim(0, 13) +
ggtitle('Percentage of runs settling on\nthe grammatical parse') +
theme_classic()
ggplot(d, aes(Condition, ProcessingTime)) +
geom_pointrange(aes(ymin=ProcessingTime-2*SE, ymax=ProcessingTime+2*SE)) +
ggtitle('Mean processing times with 95% CIs') +
theme_classic(base_size = 18)
ggplot(d, aes(Condition, ProcessingTime)) +
geom_pointrange(aes(ymin=ProcessingTime-2*SE, ymax=ProcessingTime+2*SE)) +
ggtitle('Mean processing times\nwith 95% CIs') +
theme_classic(base_size = 18)
ggplot(d, aes(Condition, PercentGrammatical)) + geom_point(size=2.5) +
ylim(0, 13) +
ggtitle('Percentage of runs settling on\nthe grammatical parse') +
theme_classic(base_size = 18)
ggplot(d, aes(Condition, PercentGrammatical)) + geom_point(size=2.5) +
ylim(0, 13) +
ggtitle('Percentage of runs settling \non the grammatical parse') +
theme_classic(base_size = 18)
install.packages('cowplots')
f1 <- ggplot(d, aes(Condition, ProcessingTime)) +
geom_pointrange(aes(ymin=ProcessingTime-2*SE, ymax=ProcessingTime+2*SE)) +
ggtitle('Mean processing times\nwith 95% CIs') +
theme_classic(base_size = 18)
f2 <- ggplot(d, aes(Condition, PercentGrammatical)) + geom_point(size=2.5) +
ylim(0, 13) +
ggtitle('Percentage of runs settling \non the grammatical parse') +
theme_classic(base_size = 18)
library(cowplots)
install.packages('cowplot', dependencies = T)
library(cowplot)
plot_grid(f1, f2)
ggsave('SimResults.pdf', width = 11, height = 8, units='in')
getwd()
setwd('~/Google Drive/UConn/Research/SmithTaborICCM2018/Presentation/PresentationFigures/')
ggsave('SimResults.pdf', width = 11, height = 5, units='in')
f1 <- ggplot(d, aes(Condition, ProcessingTime)) +
geom_pointrange(aes(ymin=ProcessingTime-2*SE, ymax=ProcessingTime+2*SE)) +
labs(y='Processing time [steps]') +
ggtitle('Mean processing times\nwith 95% CIs') +
theme_classic(base_size = 18)
f2 <- ggplot(d, aes(Condition, PercentGrammatical)) + geom_point(size=2.5) +
ylim(0, 13) +
labs(y='Percent grammatical') +
ggtitle('Percentage of runs settling \non the grammatical parse') +
theme_classic(base_size = 18)
plot_grid(f1, f2)
ggsave('SimResults.pdf', width = 11, height = 5, units='in')
